{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4c2716",
   "metadata": {},
   "source": [
    "# Synthetic Dataset Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d272436",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_digits = 5\n",
    "distribution = 'uniform'\n",
    "dataset_path = '../../data'\n",
    "model_path = '/Users/razoren/data18_5/mnist_single_digit_model.zip'\n",
    "samples_dir = '/Users/razoren/data18_5/uniform_5_digit_model/samples'\n",
    "results_dir = '/Users/razoren/uniform_5_digit_model'\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9dccee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and utils\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "import asyncio\n",
    "import csv\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22d6b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71c6017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5), std=(0.5))])\n",
    "\n",
    "images = []\n",
    "for image_path in os.listdir(samples_dir):\n",
    "    if image_path != '.DS_Store':\n",
    "        try:\n",
    "            image = Image.open(os.path.join(samples_dir, image_path))\n",
    "            image = transform(image)\n",
    "            images.append(image)\n",
    "        except PIL.UnidentifiedImageError:\n",
    "            print(\"cannotidentify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73e863cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title: str):\n",
    "    plt.figure()\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    \n",
    "def save_result_to_csv(results: list[str]):\n",
    "    path = f\"{results_dir}/{num_of_digits}_{distribution}_ocr_results.csv\"\n",
    "    with open(\n",
    "        path,\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(results)\n",
    "    print(f\"saved results to {path}\")\n",
    "\n",
    "    \n",
    "def OCR(images):\n",
    "    results = []\n",
    "    for i, image in enumerate(images):\n",
    "        num_of_digits = int(image.shape[2] / 28)\n",
    "\n",
    "        # Split the n-digit image into n same equal parts\n",
    "        res = ''\n",
    "        for i in range(num_of_digits):\n",
    "            img = image[0, :, :].view(28, 28 * num_of_digits)\n",
    "            single_digit = img[:, (i)*28:(i+1)*28]\n",
    "            single_digit_reshaped = single_digit.reshape(1, 28*28)\n",
    "\n",
    "            # Turn off gradients to speed up this part\n",
    "            with torch.no_grad():\n",
    "                logps = model(single_digit_reshaped)\n",
    "\n",
    "            # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "            ps = torch.exp(logps)\n",
    "            probab = list(ps.numpy()[0])\n",
    "            res += str(probab.index(max(probab)))\n",
    "        \n",
    "        results.append(res)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"finished {i} images\")\n",
    "            \n",
    "    save_result_to_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f843b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved results to /Users/razoren/uniform_5_digit_model/5_uniform_ocr_results.csv\n"
     ]
    }
   ],
   "source": [
    "OCR(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3113c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be287bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
